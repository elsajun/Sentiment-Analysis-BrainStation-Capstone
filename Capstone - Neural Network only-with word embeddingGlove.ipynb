{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asins</th>\n",
       "      <td>B01AHB9CN2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keys</th>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturer</th>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.dateAdded</th>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.didPurchase</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.id</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.rating</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.text</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.title</th>\n",
       "      <td>Kindle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.userCity</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.username</th>\n",
       "      <td>Adapter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      0\n",
       "id                                                 AVqkIhwDv8e3D1O-lebb\n",
       "name                  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...\n",
       "asins                                                        B01AHB9CN2\n",
       "brand                                                            Amazon\n",
       "categories            Electronics,iPad & Tablets,All Tablets,Fire Ta...\n",
       "keys                  841667104676,amazon/53004484,amazon/b01ahb9cn2...\n",
       "manufacturer                                                     Amazon\n",
       "reviews.date                                   2017-01-13T00:00:00.000Z\n",
       "reviews.dateAdded                                  2017-07-03T23:33:15Z\n",
       "reviews.dateSeen      2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z\n",
       "reviews.didPurchase                                                 NaN\n",
       "reviews.doRecommend                                                True\n",
       "reviews.id                                                          NaN\n",
       "reviews.numHelpful                                                    0\n",
       "reviews.rating                                                        5\n",
       "reviews.sourceURLs    http://reviews.bestbuy.com/3545/5620406/review...\n",
       "reviews.text          This product so far has not disappointed. My c...\n",
       "reviews.title                                                    Kindle\n",
       "reviews.userCity                                                    NaN\n",
       "reviews.userProvince                                                NaN\n",
       "reviews.username                                                Adapter"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "reviews_df = pd.read_csv('data/Amazon Reviews.csv')\n",
    "reviews_df.head(1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.drop(columns=['reviews.userCity', 'reviews.userProvince', \n",
    "                                      'reviews.id', 'reviews.didPurchase'],\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['reviews.text'].fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df[\"reviews.rating\"] = reviews_df[\"reviews.rating\"].apply(lambda x: 0 if x < 4 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='reviews.rating', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVS0lEQVR4nO3df7Bc5X3f8fcHCRMSDOHHBcsSjZigpBEkEUVVaZ2mJHiM6rYWdiCVZxKUWDPyMDgNM2k7kM7E1K5qk9ohwTGMSSAImhhUCEZlTGwGSLETBeXiUguJML4TbJAlg2woltNCR/K3f+xz49VldVl0tPfq5r5fM2f27Pec5+xzNJI+85zn7NlUFZIkHa5jZrsDkqS5zSCRJHVikEiSOjFIJEmdGCSSpE4WznYHZtppp51WS5cune1uSNKc8vjjj3+zqsYGbZt3QbJ06VLGx8dnuxuSNKck+dqhtnlpS5LUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUybz7Zrv0d9mzH/rx2e6CjkJ/7ze2j/T4jkgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInIwuSJN+XZFuS/5VkR5L/2OqnJHkwyVfa68l9ba5JMpHk6SQX99XPT7K9bbshSVr9uCR3tfpjSZaO6nwkSYONckTyKvCzVfWTwApgdZILgKuBh6pqGfBQe0+S5cBa4BxgNXBjkgXtWDcBG4BlbVnd6uuBl6rqbOB64LoRno8kaYCRBUn1fKe9PbYtBawBNrX6JuCStr4GuLOqXq2qZ4AJYFWSRcCJVbW1qgq4fUqbyWPdDVw0OVqRJM2Mkc6RJFmQ5AngBeDBqnoMOKOq9gC019Pb7ouB5/qa72q1xW19av2gNlW1H3gZOHVAPzYkGU8yvnfv3iN0dpIkGHGQVNWBqloBLKE3ujh3mt0HjSRqmvp0bab24+aqWllVK8fGxl6n15KkN2JG7tqqqv8N/Cm9uY3n2+Uq2usLbbddwJl9zZYAu1t9yYD6QW2SLAROAl4cxTlIkgYb5V1bY0l+sK0fD7wd+CtgC7Cu7bYOuK+tbwHWtjuxzqI3qb6tXf7al+SCNv9x+ZQ2k8e6FHi4zaNIkmbIKH9qdxGwqd15dQywuaruT7IV2JxkPfAscBlAVe1IshnYCewHrqyqA+1YVwC3AccDD7QF4BbgjiQT9EYia0d4PpKkAUYWJFX1ZeC8AfVvARcdos1GYOOA+jjwmvmVqnqFFkSSpNnhN9slSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdTKyIElyZpJHkjyVZEeSX231a5N8PckTbXlnX5trkkwkeTrJxX3185Nsb9tuSJJWPy7JXa3+WJKlozofSdJgoxyR7Ad+rap+DLgAuDLJ8rbt+qpa0ZbPArRta4FzgNXAjUkWtP1vAjYAy9qyutXXAy9V1dnA9cB1IzwfSdIAIwuSqtpTVV9q6/uAp4DF0zRZA9xZVa9W1TPABLAqySLgxKraWlUF3A5c0tdmU1u/G7hocrQiSZoZMzJH0i45nQc81kofSPLlJLcmObnVFgPP9TXb1WqL2/rU+kFtqmo/8DJw6oDP35BkPMn43r17j8xJSZKAGQiSJCcA9wBXVdW36V2m+mFgBbAH+PjkrgOa1zT16docXKi6uapWVtXKsbGxN3YCkqRpjTRIkhxLL0T+sKr+GKCqnq+qA1X1XeD3gFVt913AmX3NlwC7W33JgPpBbZIsBE4CXhzN2UiSBhnlXVsBbgGeqqrf6qsv6tvt3cCTbX0LsLbdiXUWvUn1bVW1B9iX5IJ2zMuB+/rarGvrlwIPt3kUSdIMWTjCY78N+EVge5InWu3XgfcmWUHvEtRXgfcDVNWOJJuBnfTu+Lqyqg60dlcAtwHHAw+0BXpBdUeSCXojkbUjPB9J0gAjC5Kq+iKD5zA+O02bjcDGAfVx4NwB9VeAyzp0U5LUkd9slyR1YpBIkjoxSCRJnRgkkqRODBJJUicGiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSCRJnRgkkqRODBJJUicGiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSCRJnRgkkqRODBJJUicGiSSpE4NEktTJyIIkyZlJHknyVJIdSX611U9J8mCSr7TXk/vaXJNkIsnTSS7uq5+fZHvbdkOStPpxSe5q9ceSLB3V+UiSBhvliGQ/8GtV9WPABcCVSZYDVwMPVdUy4KH2nrZtLXAOsBq4McmCdqybgA3AsrasbvX1wEtVdTZwPXDdCM9HkjTAyIKkqvZU1Zfa+j7gKWAxsAbY1HbbBFzS1tcAd1bVq1X1DDABrEqyCDixqrZWVQG3T2kzeay7gYsmRyuSpJkxI3Mk7ZLTecBjwBlVtQd6YQOc3nZbDDzX12xXqy1u61PrB7Wpqv3Ay8CpAz5/Q5LxJON79+49QmclSYIZCJIkJwD3AFdV1ben23VAraapT9fm4ELVzVW1sqpWjo2NvV6XJUlvwEiDJMmx9ELkD6vqj1v5+Xa5ivb6QqvvAs7sa74E2N3qSwbUD2qTZCFwEvDikT8TSdKhjPKurQC3AE9V1W/1bdoCrGvr64D7+upr251YZ9GbVN/WLn/tS3JBO+blU9pMHutS4OE2jyJJmiELR3jstwG/CGxP8kSr/TrwUWBzkvXAs8BlAFW1I8lmYCe9O76urKoDrd0VwG3A8cADbYFeUN2RZILeSGTtCM9HkjTAyIKkqr7I4DkMgIsO0WYjsHFAfRw4d0D9FVoQSZJmh99slyR1YpBIkjoZKkiSPDRMTZI0/0w7R5Lk+4DvB05rz8SanPM4EXjriPsmSZoDXm+y/f3AVfRC43G+FyTfBj45um5JkuaKaYOkqn4H+J0kv1JVn5ihPkmS5pChbv+tqk8k+SfA0v42VXX7iPolSZojhgqSJHcAPww8AUx+SXDySbySpHls2C8krgSW+/gRSdJUw36P5EngLaPsiCRpbhp2RHIasDPJNuDVyWJVvWskvZIkzRnDBsm1o+yEJGnuGvaurf8x6o5IkuamYe/a2sf3fnnwTcCxwN9U1Ymj6pgkaW4YdkTy5v73SS4BVo2iQ5KkueWwnv5bVZ8BfvbIdkWSNBcNe2nrPX1vj6H3vRK/UyJJGvqurX/Vt74f+Cqw5oj3RpI05ww7R/LLo+6IJGluGvaHrZYkuTfJC0meT3JPkiWj7pwk6eg37GT7HwBb6P0uyWLgv7eaJGmeGzZIxqrqD6pqf1tuA8ZG2C9J0hwxbJB8M8kvJFnQll8AvjXKjkmS5oZhg+R9wM8D3wD2AJcC007AJ7m1zak82Ve7NsnXkzzRlnf2bbsmyUSSp5Nc3Fc/P8n2tu2GJGn145Lc1eqPJVk69FlLko6YYYPkw8C6qhqrqtPpBcu1r9PmNmD1gPr1VbWiLZ8FSLIcWAuc09rcmGRB2/8mYAOwrC2Tx1wPvFRVZwPXA9cNeS6SpCNo2CD5iap6afJNVb0InDddg6p6FHhxyOOvAe6sqler6hlgAliVZBFwYlVtbT+qdTtwSV+bTW39buCiydGKJGnmDBskxyQ5efJNklMY/suMU30gyZfbpa/JYy4GnuvbZ1erLW7rU+sHtamq/cDLwKmDPjDJhiTjScb37t17mN2WJA0ybJB8HPjzJB9O8iHgz4HfPIzPu4neb7+voDfX8vFWHzSSqGnq07V5bbHq5qpaWVUrx8a82UySjqRhv9l+e5Jxeg9qDPCeqtr5Rj+sqp6fXE/ye8D97e0u4My+XZcAu1t9yYB6f5tdSRYCJzH8pTRJ0hEy9NN/q2pnVf1uVX3icEIEoM15THo3vd+Ch96XHde2O7HOojepvq2q9gD7klzQ5j8uB+7ra7OurV8KPNzmUSRJM+hw5zleV5JPAxcCpyXZBXwQuDDJCnqXoL4KvB+gqnYk2QzspPdQyCur6kA71BX07gA7HnigLQC3AHckmaA3Elk7qnORJB3ayIKkqt47oHzLNPtvBDYOqI8D5w6ovwJc1qWPkqTuDuuHrSRJmmSQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUyciCJMmtSV5I8mRf7ZQkDyb5Sns9uW/bNUkmkjyd5OK++vlJtrdtNyRJqx+X5K5WfyzJ0lGdiyTp0EY5IrkNWD2ldjXwUFUtAx5q70myHFgLnNPa3JhkQWtzE7ABWNaWyWOuB16qqrOB64HrRnYmkqRDGlmQVNWjwItTymuATW19E3BJX/3Oqnq1qp4BJoBVSRYBJ1bV1qoq4PYpbSaPdTdw0eRoRZI0c2Z6juSMqtoD0F5Pb/XFwHN9++1qtcVtfWr9oDZVtR94GTh10Icm2ZBkPMn43r17j9CpSJLg6JlsHzSSqGnq07V5bbHq5qpaWVUrx8bGDrOLkqRBZjpInm+Xq2ivL7T6LuDMvv2WALtbfcmA+kFtkiwETuK1l9IkSSM200GyBVjX1tcB9/XV17Y7sc6iN6m+rV3+2pfkgjb/cfmUNpPHuhR4uM2jSJJm0MJRHTjJp4ELgdOS7AI+CHwU2JxkPfAscBlAVe1IshnYCewHrqyqA+1QV9C7A+x44IG2ANwC3JFkgt5IZO2ozkWSdGgjC5Kqeu8hNl10iP03AhsH1MeBcwfUX6EFkSRp9hwtk+2SpDnKIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqZNZCZIkX02yPckTScZb7ZQkDyb5Sns9uW//a5JMJHk6ycV99fPbcSaS3JAks3E+kjSfzeaI5GeqakVVrWzvrwYeqqplwEPtPUmWA2uBc4DVwI1JFrQ2NwEbgGVtWT2D/ZckcXRd2loDbGrrm4BL+up3VtWrVfUMMAGsSrIIOLGqtlZVAbf3tZEkzZDZCpICPp/k8SQbWu2MqtoD0F5Pb/XFwHN9bXe12uK2PrX+Gkk2JBlPMr53794jeBqSpIWz9Llvq6rdSU4HHkzyV9PsO2jeo6apv7ZYdTNwM8DKlSsH7iNJOjyzMiKpqt3t9QXgXmAV8Hy7XEV7faHtvgs4s6/5EmB3qy8ZUJckzaAZD5IkP5DkzZPrwDuAJ4EtwLq22zrgvra+BVib5LgkZ9GbVN/WLn/tS3JBu1vr8r42kqQZMhuXts4A7m136i4E/qiq/iTJXwKbk6wHngUuA6iqHUk2AzuB/cCVVXWgHesK4DbgeOCBtkiSZtCMB0lV/TXwkwPq3wIuOkSbjcDGAfVx4Nwj3UdJ0vCOptt/JUlzkEEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdTJbv0cyp53/726f7S7oKPT4f7l8trsgzQpHJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqZM5HyRJVid5OslEkqtnuz+SNN/M6SBJsgD4JPDPgeXAe5Msn91eSdL8MqeDBFgFTFTVX1fV/wPuBNbMcp8kaV6Z64+RXww81/d+F/CPpu6UZAOwob39TpKnZ6Bv88VpwDdnuxNHg3xs3Wx3QQfz7+akD+ZIHOWHDrVhrgfJoD+dek2h6mbg5tF3Z/5JMl5VK2e7H9JU/t2cOXP90tYu4My+90uA3bPUF0mal+Z6kPwlsCzJWUneBKwFtsxynyRpXpnTl7aqan+SDwCfAxYAt1bVjlnu1nzjJUMdrfy7OUNS9ZopBUmShjbXL21JkmaZQSJJ6sQg0WHx0TQ6WiW5NckLSZ6c7b7MFwaJ3jAfTaOj3G3A6tnuxHxikOhw+GgaHbWq6lHgxdnux3xikOhwDHo0zeJZ6oukWWaQ6HAM9WgaSfODQaLD4aNpJP0tg0SHw0fTSPpbBonesKraD0w+muYpYLOPptHRIsmnga3AjybZlWT9bPfp7zofkSJJ6sQRiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSKQOkrw1yd2z3Y9JSVYkeWff+3f5dGaNmrf/Sn2ShN6/i+/Odl8OJcnC9l2eQdt+CVhZVR+Y2V5pPjNINO8lWQo8ADwC/GPgM8C/BI4D7q2qDya5DvhaVd3Y2lwL7APuAe6vqnPb4/U/ClzY2n6yqj6V5EbgT6pqS5J7gZeq6n3ti3JnAR8BNtN71MwC4MNVddeUPt5G74m25wFfAu4Cfhs4Hvi/wC8DzwATrfb1dtzjacHSjvFtYCXwFuDfV9XdSY4Bfhf4Z+0YxwC3VtVRM9LS0W3hbHdAOkr8KL3/jD8DXErvUfkBtiT5aXqPyv9t4Ma2/8/T+82L/svD64GXq+ofJjkO+LMknwceBf4pvcfILAYWtf1/qh13NbC7qv4FQJKTDtHHHwHeXlUHkpwI/HRV7U/yduA/V9XPJfkN+kYkbYTSb1H73L/f+nM38B5gKfDjwOn0nlZw6+v/kUk9BonU87Wq+oskHwPeAfzPVj8BWFZVtyQ5PclbgTF6o4pn22hm0juAn0hyaXt/ErAM+AJwVfvxr53AyUkW0Rv9/Bt6/7l/rI167q+qLxyij/+tqg70HXtTkmX0nrx87JDn+Zl22W5nkjNa7afasb8LfCPJI0MeSwIMEmnS37TXAB+pqk8N2OdueqOVt9AbSUwV4Feq6nOv2ZCcTG/k8ShwCr0RzXeqah+wL8n5wDuBjyT5fFV9aJo+AnwYeKSq3t3C7E9f/xQBeHVKf/tfpcPiXVvSwT4HvC/JCQBJFic5vW27k96Tji+lFyqD2l6R5NjW9keS/EDbthW4il6QfAH4t+2VNsr5P1X1X4GPAf9giH6eRG8eBOCX+ur7gDcP0b7fF4GfS3JMG6Vc+Abba54zSKQ+VfV54I+ArUm20wuMN7dtO9r616tqz4Dmv0/v0tWXkjwJfIrvjfq/ACysqgl6k+WntBr05ia2JXkC+A/AfwJI8qEk7zpEV3+T3ujlz+hN0E96BFie5Ikk/3rI076H3m/MTPb5MeDlIdtK3rUlCZKcUFXfSXIqsA14W1V9Y7b7pbnBORJJAPcn+UHgTfRuPzZENDRHJJKkTpwjkSR1YpBIkjoxSCRJnRgkkqRODBJJUif/H5EIDCqNkNe/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(reviews_df['reviews.rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score negative (%):0.067\n",
      "Score positive (%):0.933\n"
     ]
    }
   ],
   "source": [
    "# print(\"Score negative (%):\" + str(round(len(reviews_df[reviews_df['reviews.rating']==-1])/len(reviews_df['reviews.rating']),3)))\n",
    "print(\"Score negative (%):\" + str(round(len(reviews_df[reviews_df['reviews.rating']==0])/len(reviews_df['reviews.rating']),3)))\n",
    "print(\"Score positive (%):\" + str(round(len(reviews_df[reviews_df['reviews.rating']==1])/len(reviews_df['reviews.rating']),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "ENGLISH_STOP_WORDS.remove('not')\n",
    "ENGLISH_STOP_WORDS.remove('no')\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    \n",
    "    for punctuation_mark in string.punctuation:\n",
    "        # Remove punctuation and set to lower case\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    # split sentence into words\n",
    "    listofwords = sentence.split(' ')\n",
    "    listofstemmed_words = []\n",
    "    \n",
    "        \n",
    "    # Remove stopwords and any tokens that are just empty strings\n",
    "    for word in listofwords:\n",
    "        if (not word in ENGLISH_STOP_WORDS) and (word!=''):\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            listofstemmed_words.append(stemmed_word)\n",
    "\n",
    "    return listofstemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews_df['reviews.text']\n",
    "y = reviews_df['reviews.rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Taking a chuck for our 20% test set\n",
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, stratify=y, test_size=0.25)\n",
    "\n",
    "# Splitting the remainder in two chunks\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_remainder, \n",
    "                                                                y_remainder, \n",
    "                                                                stratify=y_remainder, test_size=0.25)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "bagofwords = CountVectorizer(stop_words=\"english\", min_df = 10, # ngram_range = (1,3),\n",
    "                             tokenizer=my_tokenizer)\n",
    "bagofwords.fit(X_train)\n",
    "X_train = bagofwords.transform(X_train)\n",
    "X_validation = bagofwords.transform(X_validation)\n",
    "X_test = bagofwords.transform(X_test)\n",
    "X_remainder = bagofwords.transform(X_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = X_validation.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "610/610 - 2s - loss: 0.2114 - accuracy: 0.9352 - val_loss: 0.1805 - val_accuracy: 0.9417\n",
      "Epoch 2/100\n",
      "610/610 - 2s - loss: 0.1321 - accuracy: 0.9547 - val_loss: 0.1989 - val_accuracy: 0.9369\n",
      "Epoch 3/100\n",
      "610/610 - 2s - loss: 0.0639 - accuracy: 0.9798 - val_loss: 0.2841 - val_accuracy: 0.9356\n",
      "Epoch 4/100\n",
      "610/610 - 2s - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.5025 - val_accuracy: 0.9295\n",
      "Epoch 5/100\n",
      "610/610 - 2s - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.5146 - val_accuracy: 0.9356\n",
      "Epoch 6/100\n",
      "610/610 - 2s - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.5652 - val_accuracy: 0.9280\n",
      "Epoch 7/100\n",
      "610/610 - 2s - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.4935 - val_accuracy: 0.9297\n",
      "Epoch 8/100\n",
      "610/610 - 2s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6627 - val_accuracy: 0.9323\n",
      "Epoch 9/100\n",
      "610/610 - 2s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6784 - val_accuracy: 0.9313\n",
      "Epoch 10/100\n",
      "610/610 - 2s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.6936 - val_accuracy: 0.9280\n",
      "Epoch 11/100\n",
      "610/610 - 2s - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.7565 - val_accuracy: 0.9316\n",
      "Epoch 12/100\n",
      "610/610 - 3s - loss: 9.4140e-04 - accuracy: 0.9996 - val_loss: 0.7969 - val_accuracy: 0.9309\n",
      "Epoch 13/100\n",
      "610/610 - 3s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.7685 - val_accuracy: 0.9319\n",
      "Epoch 14/100\n",
      "610/610 - 3s - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.7685 - val_accuracy: 0.9273\n",
      "Epoch 15/100\n",
      "610/610 - 2s - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.8635 - val_accuracy: 0.9311\n",
      "Epoch 16/100\n",
      "610/610 - 2s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.7636 - val_accuracy: 0.9265\n",
      "Epoch 17/100\n",
      "610/610 - 2s - loss: 7.9733e-04 - accuracy: 0.9997 - val_loss: 0.8789 - val_accuracy: 0.9282\n",
      "Epoch 18/100\n",
      "610/610 - 2s - loss: 6.8853e-04 - accuracy: 0.9997 - val_loss: 1.0311 - val_accuracy: 0.9314\n",
      "Epoch 19/100\n",
      "610/610 - 2s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.7633 - val_accuracy: 0.9316\n",
      "Epoch 20/100\n",
      "610/610 - 2s - loss: 7.4233e-04 - accuracy: 0.9997 - val_loss: 0.8648 - val_accuracy: 0.9328\n",
      "Epoch 21/100\n",
      "610/610 - 2s - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6920 - val_accuracy: 0.9303\n",
      "Epoch 22/100\n",
      "610/610 - 3s - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4534 - val_accuracy: 0.9267\n",
      "Epoch 23/100\n",
      "610/610 - 2s - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6252 - val_accuracy: 0.9314\n",
      "Epoch 24/100\n",
      "610/610 - 2s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.7786 - val_accuracy: 0.9305\n",
      "Epoch 25/100\n",
      "610/610 - 2s - loss: 8.2251e-04 - accuracy: 0.9997 - val_loss: 0.7160 - val_accuracy: 0.9250\n",
      "Epoch 26/100\n",
      "610/610 - 2s - loss: 7.9042e-04 - accuracy: 0.9997 - val_loss: 0.8346 - val_accuracy: 0.9274\n",
      "Epoch 27/100\n",
      "610/610 - 2s - loss: 6.8738e-04 - accuracy: 0.9997 - val_loss: 0.8933 - val_accuracy: 0.9293\n",
      "Epoch 28/100\n",
      "610/610 - 3s - loss: 6.5478e-04 - accuracy: 0.9997 - val_loss: 0.8345 - val_accuracy: 0.9283\n",
      "Epoch 29/100\n",
      "610/610 - 2s - loss: 6.9700e-04 - accuracy: 0.9997 - val_loss: 0.9328 - val_accuracy: 0.9325\n",
      "Epoch 30/100\n",
      "610/610 - 2s - loss: 8.3676e-04 - accuracy: 0.9997 - val_loss: 1.0217 - val_accuracy: 0.9312\n",
      "Epoch 31/100\n",
      "610/610 - 2s - loss: 6.7723e-04 - accuracy: 0.9997 - val_loss: 1.0481 - val_accuracy: 0.9314\n",
      "Epoch 32/100\n",
      "610/610 - 2s - loss: 9.5816e-04 - accuracy: 0.9996 - val_loss: 0.8290 - val_accuracy: 0.9306\n",
      "Epoch 33/100\n",
      "610/610 - 2s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.1153 - val_accuracy: 0.9343\n",
      "Epoch 34/100\n",
      "610/610 - 2s - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.6979 - val_accuracy: 0.9235\n",
      "Epoch 35/100\n",
      "610/610 - 2s - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.8024 - val_accuracy: 0.9291\n",
      "Epoch 36/100\n",
      "610/610 - 2s - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.6559 - val_accuracy: 0.9279\n",
      "Epoch 37/100\n",
      "610/610 - 2s - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.7227 - val_accuracy: 0.9250\n",
      "Epoch 38/100\n",
      "610/610 - 2s - loss: 6.8649e-04 - accuracy: 0.9997 - val_loss: 0.7933 - val_accuracy: 0.9273\n",
      "Epoch 39/100\n",
      "610/610 - 2s - loss: 6.7565e-04 - accuracy: 0.9997 - val_loss: 0.8353 - val_accuracy: 0.9289\n",
      "Epoch 40/100\n",
      "610/610 - 2s - loss: 6.6930e-04 - accuracy: 0.9997 - val_loss: 0.8409 - val_accuracy: 0.9291\n",
      "Epoch 41/100\n",
      "610/610 - 2s - loss: 6.1448e-04 - accuracy: 0.9997 - val_loss: 1.0181 - val_accuracy: 0.9299\n",
      "Epoch 42/100\n",
      "610/610 - 2s - loss: 6.5545e-04 - accuracy: 0.9997 - val_loss: 0.9305 - val_accuracy: 0.9293\n",
      "Epoch 43/100\n",
      "610/610 - 2s - loss: 6.9013e-04 - accuracy: 0.9997 - val_loss: 1.0373 - val_accuracy: 0.9303\n",
      "Epoch 44/100\n",
      "610/610 - 2s - loss: 6.7975e-04 - accuracy: 0.9997 - val_loss: 0.9959 - val_accuracy: 0.9297\n",
      "Epoch 45/100\n",
      "610/610 - 2s - loss: 6.6107e-04 - accuracy: 0.9997 - val_loss: 1.2222 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "610/610 - 2s - loss: 6.6323e-04 - accuracy: 0.9997 - val_loss: 1.2181 - val_accuracy: 0.9323\n",
      "Epoch 47/100\n",
      "610/610 - 2s - loss: 6.7127e-04 - accuracy: 0.9997 - val_loss: 1.2617 - val_accuracy: 0.9316\n",
      "Epoch 48/100\n",
      "610/610 - 2s - loss: 6.7099e-04 - accuracy: 0.9997 - val_loss: 1.2735 - val_accuracy: 0.9316\n",
      "Epoch 49/100\n",
      "610/610 - 2s - loss: 6.8550e-04 - accuracy: 0.9997 - val_loss: 1.2795 - val_accuracy: 0.9317\n",
      "Epoch 50/100\n",
      "610/610 - 2s - loss: 6.7840e-04 - accuracy: 0.9997 - val_loss: 1.3849 - val_accuracy: 0.9320\n",
      "Epoch 51/100\n",
      "610/610 - 2s - loss: 7.3961e-04 - accuracy: 0.9997 - val_loss: 1.4358 - val_accuracy: 0.9325\n",
      "Epoch 52/100\n",
      "610/610 - 2s - loss: 6.7558e-04 - accuracy: 0.9997 - val_loss: 1.5996 - val_accuracy: 0.9335\n",
      "Epoch 53/100\n",
      "610/610 - 2s - loss: 6.8601e-04 - accuracy: 0.9997 - val_loss: 1.6052 - val_accuracy: 0.9332\n",
      "Epoch 54/100\n",
      "610/610 - 2s - loss: 6.8358e-04 - accuracy: 0.9997 - val_loss: 1.6180 - val_accuracy: 0.9331\n",
      "Epoch 55/100\n",
      "610/610 - 2s - loss: 6.5218e-04 - accuracy: 0.9997 - val_loss: 1.5890 - val_accuracy: 0.9324\n",
      "Epoch 56/100\n",
      "610/610 - 2s - loss: 6.6741e-04 - accuracy: 0.9997 - val_loss: 1.6637 - val_accuracy: 0.9328\n",
      "Epoch 57/100\n",
      "610/610 - 2s - loss: 6.4566e-04 - accuracy: 0.9997 - val_loss: 1.7006 - val_accuracy: 0.9327\n",
      "Epoch 58/100\n",
      "610/610 - 2s - loss: 6.5653e-04 - accuracy: 0.9997 - val_loss: 1.5809 - val_accuracy: 0.9314\n",
      "Epoch 59/100\n",
      "610/610 - 2s - loss: 6.5993e-04 - accuracy: 0.9997 - val_loss: 1.8117 - val_accuracy: 0.9328\n",
      "Epoch 60/100\n",
      "610/610 - 2s - loss: 6.3095e-04 - accuracy: 0.9997 - val_loss: 2.3838 - val_accuracy: 0.9339\n",
      "Epoch 61/100\n",
      "610/610 - 2s - loss: 0.0080 - accuracy: 0.9990 - val_loss: 1.3720 - val_accuracy: 0.9226\n",
      "Epoch 62/100\n",
      "610/610 - 2s - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.9814 - val_accuracy: 0.9278\n",
      "Epoch 63/100\n",
      "610/610 - 2s - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.7214 - val_accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "610/610 - 2s - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.7252 - val_accuracy: 0.9233\n",
      "Epoch 65/100\n",
      "610/610 - 2s - loss: 9.3170e-04 - accuracy: 0.9996 - val_loss: 0.7848 - val_accuracy: 0.9246\n",
      "Epoch 66/100\n",
      "610/610 - 2s - loss: 8.0906e-04 - accuracy: 0.9997 - val_loss: 0.8774 - val_accuracy: 0.9278\n",
      "Epoch 67/100\n",
      "610/610 - 2s - loss: 6.5561e-04 - accuracy: 0.9997 - val_loss: 0.9859 - val_accuracy: 0.9280\n",
      "Epoch 68/100\n",
      "610/610 - 2s - loss: 6.5002e-04 - accuracy: 0.9997 - val_loss: 0.9994 - val_accuracy: 0.9276\n",
      "Epoch 69/100\n",
      "610/610 - 2s - loss: 6.3308e-04 - accuracy: 0.9997 - val_loss: 1.1025 - val_accuracy: 0.9287\n",
      "Epoch 70/100\n",
      "610/610 - 2s - loss: 6.2713e-04 - accuracy: 0.9997 - val_loss: 1.2169 - val_accuracy: 0.9304\n",
      "Epoch 71/100\n",
      "610/610 - 2s - loss: 6.5124e-04 - accuracy: 0.9997 - val_loss: 1.1748 - val_accuracy: 0.9284\n",
      "Epoch 72/100\n",
      "610/610 - 2s - loss: 6.1293e-04 - accuracy: 0.9997 - val_loss: 1.4163 - val_accuracy: 0.9313\n",
      "Epoch 73/100\n",
      "610/610 - 2s - loss: 6.6292e-04 - accuracy: 0.9997 - val_loss: 1.3916 - val_accuracy: 0.9308\n",
      "Epoch 74/100\n",
      "610/610 - 2s - loss: 6.2524e-04 - accuracy: 0.9997 - val_loss: 1.4402 - val_accuracy: 0.9306\n",
      "Epoch 75/100\n",
      "610/610 - 2s - loss: 6.3018e-04 - accuracy: 0.9997 - val_loss: 1.5047 - val_accuracy: 0.9305\n",
      "Epoch 76/100\n",
      "610/610 - 2s - loss: 6.7606e-04 - accuracy: 0.9996 - val_loss: 1.4506 - val_accuracy: 0.9301\n",
      "Epoch 77/100\n",
      "610/610 - 2s - loss: 6.2738e-04 - accuracy: 0.9997 - val_loss: 1.6709 - val_accuracy: 0.9328\n",
      "Epoch 78/100\n",
      "610/610 - 2s - loss: 6.4559e-04 - accuracy: 0.9997 - val_loss: 1.7159 - val_accuracy: 0.9327\n",
      "Epoch 79/100\n",
      "610/610 - 2s - loss: 7.1089e-04 - accuracy: 0.9997 - val_loss: 1.9337 - val_accuracy: 0.9325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "610/610 - 2s - loss: 6.3371e-04 - accuracy: 0.9997 - val_loss: 2.0091 - val_accuracy: 0.9319\n",
      "Epoch 81/100\n",
      "610/610 - 2s - loss: 6.2843e-04 - accuracy: 0.9997 - val_loss: 2.1061 - val_accuracy: 0.9326\n",
      "Epoch 82/100\n",
      "610/610 - 2s - loss: 7.5126e-04 - accuracy: 0.9997 - val_loss: 1.7645 - val_accuracy: 0.9316\n",
      "Epoch 83/100\n",
      "610/610 - 2s - loss: 6.1848e-04 - accuracy: 0.9997 - val_loss: 1.9679 - val_accuracy: 0.9321\n",
      "Epoch 84/100\n",
      "610/610 - 3s - loss: 6.3403e-04 - accuracy: 0.9997 - val_loss: 1.9454 - val_accuracy: 0.9302\n",
      "Epoch 85/100\n",
      "610/610 - 2s - loss: 6.2957e-04 - accuracy: 0.9997 - val_loss: 2.0573 - val_accuracy: 0.9306\n",
      "Epoch 86/100\n",
      "610/610 - 3s - loss: 6.3305e-04 - accuracy: 0.9997 - val_loss: 2.1349 - val_accuracy: 0.9317\n",
      "Epoch 87/100\n",
      "610/610 - 2s - loss: 6.7489e-04 - accuracy: 0.9997 - val_loss: 2.0520 - val_accuracy: 0.9304\n",
      "Epoch 88/100\n",
      "610/610 - 2s - loss: 5.8321e-04 - accuracy: 0.9997 - val_loss: 2.4892 - val_accuracy: 0.9326\n",
      "Epoch 89/100\n",
      "610/610 - 2s - loss: 6.4642e-04 - accuracy: 0.9997 - val_loss: 2.4490 - val_accuracy: 0.9327\n",
      "Epoch 90/100\n",
      "610/610 - 2s - loss: 6.4510e-04 - accuracy: 0.9997 - val_loss: 2.4044 - val_accuracy: 0.9326\n",
      "Epoch 91/100\n",
      "610/610 - 2s - loss: 6.6683e-04 - accuracy: 0.9997 - val_loss: 2.4040 - val_accuracy: 0.9327\n",
      "Epoch 92/100\n",
      "610/610 - 2s - loss: 6.3071e-04 - accuracy: 0.9997 - val_loss: 2.5361 - val_accuracy: 0.9341\n",
      "Epoch 93/100\n",
      "610/610 - 3s - loss: 7.0428e-04 - accuracy: 0.9997 - val_loss: 2.1662 - val_accuracy: 0.9290\n",
      "Epoch 94/100\n",
      "610/610 - 2s - loss: 6.2591e-04 - accuracy: 0.9997 - val_loss: 2.5323 - val_accuracy: 0.9319\n",
      "Epoch 95/100\n",
      "610/610 - 2s - loss: 6.4180e-04 - accuracy: 0.9997 - val_loss: 2.6180 - val_accuracy: 0.9321\n",
      "Epoch 96/100\n",
      "610/610 - 2s - loss: 6.3123e-04 - accuracy: 0.9997 - val_loss: 2.5830 - val_accuracy: 0.9313\n",
      "Epoch 97/100\n",
      "610/610 - 2s - loss: 6.4172e-04 - accuracy: 0.9997 - val_loss: 2.8442 - val_accuracy: 0.9319\n",
      "Epoch 98/100\n",
      "610/610 - 3s - loss: 5.9405e-04 - accuracy: 0.9997 - val_loss: 3.7326 - val_accuracy: 0.9340\n",
      "Epoch 99/100\n",
      "610/610 - 2s - loss: 8.9537e-04 - accuracy: 0.9997 - val_loss: 2.2944 - val_accuracy: 0.9323\n",
      "Epoch 100/100\n",
      "610/610 - 2s - loss: 6.1187e-04 - accuracy: 0.9997 - val_loss: 2.5791 - val_accuracy: 0.9334\n",
      "51/51 - 0s - loss: 2.3960 - accuracy: 0.9351\n",
      "0.9350669384002686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train.values, epochs=100, batch_size=32, verbose=2, validation_data=(X_test, y_test.values))\n",
    "\n",
    "score = model.evaluate(X_validation, y_validation.values, batch_size=128, verbose=2)\n",
    "print (score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "ENGLISH_STOP_WORDS.remove('not')\n",
    "ENGLISH_STOP_WORDS.remove('no')\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    \n",
    "    for punctuation_mark in string.punctuation:\n",
    "        # Remove punctuation and set to lower case\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    # split sentence into words\n",
    "    listofwords = sentence.split(' ')\n",
    "    listofstemmed_words = []\n",
    "    \n",
    "        \n",
    "    # Remove stopwords and any tokens that are just empty strings\n",
    "    for word in listofwords:\n",
    "        if (not word in ENGLISH_STOP_WORDS) and (word!=''):\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            listofstemmed_words.append(stemmed_word)\n",
    "            \n",
    "    #listofstemmed_words = np.array(listofstemmed_words)\n",
    "    return listofstemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [product, far, not, disappoint, children, love...\n",
       "1    [great, beginn, experienc, person, bought, gif...\n",
       "2    [inexpens, tablet, use, learn, step, nabi, thr...\n",
       "3    [ive, fire, hd, 8, two, week, love, tablet, gr...\n",
       "4    [bought, grand, daughter, come, visit, set, us...\n",
       "5    [amazon, fire, 8, inch, tablet, perfect, size,...\n",
       "6    [great, eread, go, nice, light, weight, price,...\n",
       "7    [gave, christma, gift, inlaw, husband, uncl, l...\n",
       "8    [great, devic, read, book, like, link, borrow,...\n",
       "9                    [love, order, book, read, reader]\n",
       "Name: stemmed_tokens, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "\n",
    "reviews_df['stemmed_tokens'] = [my_tokenizer(sentence) for sentence in reviews_df['reviews.text'].values]\n",
    "reviews_df['stemmed_tokens'] .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews_df['reviews.text']\n",
    "y = reviews_df['reviews.rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.values.reshape((len(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y.values.reshape((len(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Taking a chuck for our 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This product so far has not disappointed. My children love to use it and I like the ability to monitor control what content they see with ease.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25995,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"The text is easier to read and I don't have to have a light in order to read when the room light is dim or if it is dark.\",\n",
       "       \"I love my Echo Tap! I have my own personal alarm, informs me on today's weather forcast and local events. Great purchase.\",\n",
       "       'Makes reading books easier. I love it! User friendly too!', ...,\n",
       "       \"We have had a Fire Stick for quite some time that we use for our Playstation Vue subscription. I decided to purchase the Fire TV as a second Playstation Vue device because it has the wired ethernet option, and WiFi isn't a reliably fast enough connection for the streaming services. The Fire TV performs wonderfully, and is much snappier in performance than the Stick even in the menus. Our Apple TV has now been unused for several months.\",\n",
       "       \"I previously had bought an older model of these tablets for my children. I wasn't to happy with them. But this tablet is great, it has child safety features like wether you would like to have them surf the web to even limiting the amount of hours your child can use it. Very good tablet for what my kids will use it for which is mostly Netflix Hulu and even though there isn't you tube app there are alternate apps that acces you tube.\",\n",
       "       'the reason i purchase the item because she love to watch movies on her phone.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews.text\n",
       "True    25995\n",
       "Name: reviews.text, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby(X_train.map(type).eq(str)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train) # equivalent to .fit(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train) # equivalent to .transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 2D arrays into tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_data.shuffle(1000).padded_batch(36459)\n",
    "test_batches = test_data.shuffle(1000).padded_batch(36459)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'son is enjoying the whole tablet. He is glad it is a quality product, bought from our favorite store.',\n",
       "       b'I have been very satisfied with my new kindle and use it almost every day!',\n",
       "       b\"Works great for Vue, and other apps if you don't have a smart TV. Better quality on Vue than my PS4\",\n",
       "       ...,\n",
       "       b'I have enjoyed becoming familiar with all the services available on my kindle!',\n",
       "       b\"I have read books on my phone and IPad and Kindle.....but rarely would read long due to disraction of other apps and email.....or couldn't read outside because of glare.....well this product has solved all my problems.....no distractions....just read and read for hours now....and can comfortably read outside or on the back end of our motorcylce if I want becasue NO GLARE!!!!! Love it :)\",\n",
       "       b'I bought this for my ten year old daughter. This is so much better than carringing around a bunch of heavy books. The battery also lasts forever'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch, train_labels = next(iter(train_batches))\n",
    "train_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 13.99494743347168\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "# Skip-gram model (sg = 1)\n",
    "size = 1000\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "# word2vec_model_file = 'word2vec_' + str(size) + '.model'\n",
    "start_time = time.time()\n",
    "stemmed_tokens = pd.Series(reviews_df['stemmed_tokens']).values\n",
    "# Train the Word2Vec Model\n",
    "w2v_model = Word2Vec(stemmed_tokens, min_count = min_count, size = size, workers = workers, window = window, sg = sg)\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "# model.save(word2vec_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14225\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.vocab)\n",
    "print('Vocabulary size: %d' % len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          227600    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 227,889\n",
      "Trainable params: 227,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Embedding(len(words), embedding_dim),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sequential_1/Cast (defined at <ipython-input-56-371ca51ad9f7>:5) ]] [Op:__inference_train_function_182522]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-371ca51ad9f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sequential_1/Cast (defined at <ipython-input-56-371ca51ad9f7>:5) ]] [Op:__inference_train_function_182522]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
